<!DOCTYPE html>
<html>
  <head>
  <meta charset='UTF-8'>
  <title>CoffeeScript API Documentation</title>
  <script src='../javascript/application.js'></script>
  <script src='../javascript/search.js'></script>
  <link rel='stylesheet' href='../stylesheets/application.css' type='text/css'>
</head>
  <body>
    <div id='base' data-path='../'></div>
<div id='header'>
  <div id='menu'>
    <a href='../extra/README.md.html' title='Diffbot-coffee'>
      Diffbot-coffee
    </a>
    &raquo;
    <a href='../alphabetical_index.html' title='Index'>
      Index
    </a>
    &raquo;
    <span class='title'>Crawlbot</span>
  </div>
</div>
    <div id='content'>
      <h1>
        Class:
        Crawlbot
      </h1>
      <table class='box'>
        <tr>
          <td>Defined in:</td>
          <td>src\api.coffee</td>
        </tr>
      </table>
      <h2>Overview</h2>
      <div class='docstring'>
  <p>Crawlbot class provides access to <a href="http://www.diffbot.com/dev/docs/crawl/">Crawlbot API</a></p><p>The Crawlbot API allows you to programmatically manage <a href="http://www.diffbot.com/dev/crawl/v2">Crawlbot</a> crawls and retrieve output.</p>
</div>
<div class='tags'>
</div>
      <h2>Instance Method Summary</h2>
      <ul class='summary'>
  <li>
    <span class='signature'>
      <a href='#create-dynamic'>
        #
(void)
<b>create</b><span>(callback)</span>
      </a>
    </span>
    <span class='bound note title'>Bound</span>
    <span class='desc'>
      Creates new crawlbot information to DiffBot server 
    </span>
  </li>
  <li>
    <span class='signature'>
      <a href='#pause-dynamic'>
        #
(void)
<b>pause</b><span>(callback)</span>
      </a>
    </span>
    <span class='bound note title'>Bound</span>
    <span class='desc'>
      Pauses crawlbot job 
    </span>
  </li>
  <li>
    <span class='signature'>
      <a href='#resume-dynamic'>
        #
(void)
<b>resume</b><span>(callback)</span>
      </a>
    </span>
    <span class='bound note title'>Bound</span>
    <span class='desc'>
      Resumes paused crawlbot job 
    </span>
  </li>
  <li>
    <span class='signature'>
      <a href='#restart-dynamic'>
        #
(void)
<b>restart</b><span>(callback)</span>
      </a>
    </span>
    <span class='bound note title'>Bound</span>
    <span class='desc'>
      Removes all crawled data while maintaining crawl settings 
    </span>
  </li>
  <li>
    <span class='signature'>
      <a href='#delete-dynamic'>
        #
(void)
<b>delete</b><span>(callback)</span>
      </a>
    </span>
    <span class='bound note title'>Bound</span>
    <span class='desc'>
      Deletes a crawl, and all associated data, completely. 
    </span>
  </li>
  <li>
    <span class='signature'>
      <a href='#data-dynamic'>
        #
(void)
<b>data</b><span>(callback)</span>
      </a>
    </span>
    <span class='bound note title'>Bound</span>
    <span class='desc'>
      Returns crawlbot job data 
    </span>
  </li>
  <li>
    <span class='signature'>
      <a href='#status-dynamic'>
        #
(void)
<b>status</b><span>(callback)</span>
      </a>
    </span>
    <span class='bound note title'>Bound</span>
    <span class='desc'>
      Returns crawlbot job status 
    </span>
  </li>
</ul>
      <h2>Constructor Details</h2>
      <div class='methods'>
  <div class='method_details'>
    <p class='signature' id='constructor-dynamic'>
      #
(void)
<b>constructor</b><span>(api, name, seeds, apiUrl, urlCrawlPattern, urlCrawlRegEx, urlProcessPattern, urlProcessRegEx, pageProcessPattern, maxToCrawl, maxToProcess, restrictDomain, notifyEmail, notifyWebHook, crawlDelay, repeat, onlyProcessIfNew, maxRounds)</span>
      <br>
    </p>
    <div class='docstring'>
  <p>Constructs new Crawlbot</p>
</div>
<div class='tags'>
  <h3>Parameters:</h3>
  <ul class='param'>
    <li>
      <span class='name'>api</span>
      <span class='type'>
        (<tt>Object</tt>)
      </span>
      &mdash;
      <span class='desc'>Client instance </span>
    </li>
    <li>
      <span class='name'>name</span>
      <span class='type'>
        (<tt>String</tt>)
      </span>
      &mdash;
      <span class='desc'>crawlbot unique name </span>
    </li>
    <li>
      <span class='name'>seeds</span>
      <span class='type'>
        (<tt>Array</tt>)
      </span>
      &mdash;
      <span class='desc'>Seed URL(s). Must be URL encoded. By default Crawlbot will spider subdomains (e.g., a seed URL of &quot;<a href="http://www.diffbot.com">http://www.diffbot.com</a>&quot; will include URLs at &quot;<a href="http://blog.diffbot.com">http://blog.diffbot.com</a>&quot;) (optional) </span>
    </li>
    <li>
      <span class='name'>apiUrl</span>
      <span class='type'>
        (<tt>String</tt>)
      </span>
      &mdash;
      <span class='desc'>Full Diffbot API URL through which to process pages. E.g., <code>http://api.diffbot.com/v2/article</code> to process matching links via the Article API (optional) </span>
    </li>
    <li>
      <span class='name'>urlCrawlPattern</span>
      <span class='type'>
        (<tt>Array</tt>)
      </span>
      &mdash;
      <span class='desc'>Array of strings to limit pages crawled to those whose URLs contain any of the content strings. You can use the exclamation point to specify a negative string, e.g. <code>!product</code> to exclude URLs containing the string &quot;product.&quot; (optional) </span>
    </li>
    <li>
      <span class='name'>urlCrawlRegEx</span>
      <span class='type'>
        (<tt>String</tt>)
      </span>
      &mdash;
      <span class='desc'>Specify a regular expression to limit pages crawled to those URLs that match your expression. This will override any <code>urlCrawlPattern</code> value. (optional) </span>
    </li>
    <li>
      <span class='name'>urlProcessPattern</span>
      <span class='type'>
        (<tt>Array</tt>)
      </span>
      &mdash;
      <span class='desc'>Array of strings to limit pages processed to those whose URLs contain any of the content strings. You can use the exclamation point to specify a negative string, e.g. !/category to exclude URLs containing the string &quot;/category.&quot; (optional) </span>
    </li>
    <li>
      <span class='name'>urlProcessRegEx</span>
      <span class='type'>
        (<tt>String</tt>)
      </span>
      &mdash;
      <span class='desc'>Specify a regular expression to limit pages processed to those URLs that match your expression. This will override any urlProcessPattern value. (optional) </span>
    </li>
    <li>
      <span class='name'>pageProcessPattern</span>
      <span class='type'>
        (<tt>Array</tt>)
      </span>
      &mdash;
      <span class='desc'>Array of strings to limit pages processed to those whose HTML contains any of the content strings. (optional) </span>
    </li>
    <li>
      <span class='name'>maxToCrawl</span>
      <span class='type'>
        (<tt>Number</tt>)
      </span>
      &mdash;
      <span class='desc'>Specify max pages to spider. (optional) </span>
    </li>
    <li>
      <span class='name'>maxToProcess</span>
      <span class='type'>
        (<tt>Number</tt>)
      </span>
      &mdash;
      <span class='desc'>Specify max pages to process through Diffbot APIs. Default: 10,000. (optional) </span>
    </li>
    <li>
      <span class='name'>restrictDomain</span>
      <span class='type'>
        (<tt>Number</tt>)
      </span>
      &mdash;
      <span class='desc'>By default crawls will restrict to subdomains within the seed URL domain. Specify <code>restrictDomain=0</code> to follow all links regardless of domain. (optional) </span>
    </li>
    <li>
      <span class='name'>notifyEmail</span>
      <span class='type'>
        (<tt>String</tt>)
      </span>
      &mdash;
      <span class='desc'>Send a message to this email address when the crawl hits the <code>maxToCrawl</code> or <code>maxToProcess</code> limit, or when the crawl completes. (optional) </span>
    </li>
    <li>
      <span class='name'>notifyWebHook</span>
      <span class='type'>
        (<tt>String</tt>)
      </span>
      &mdash;
      <span class='desc'>Pass a URL to be notified when the crawl hits the <code>maxToCrawl</code> or <code>maxToProcess</code> limit, or when the crawl completes. You will receive a POST with <code>X-Crawl-Name</code> and <code>X-Crawl-Status</code> in the headers, and the full JSON response in the POST body. (optional) </span>
    </li>
    <li>
      <span class='name'>crawlDelay</span>
      <span class='type'>
        (<tt>Number</tt>)
      </span>
      &mdash;
      <span class='desc'>Wait this many seconds between each URL crawled from a single IP address. Specify the number of seconds as an integer or floating-point number (e.g., 0.25). (optional) </span>
    </li>
    <li>
      <span class='name'>repeat</span>
      <span class='type'>
        (<tt>Number</tt>)
      </span>
      &mdash;
      <span class='desc'>Specify the number of days as a floating-point (e.g. <code>7.0</code>) to repeat this crawl. By default crawls will not be repeated. (optional) </span>
    </li>
    <li>
      <span class='name'>onlyProcessIfNew</span>
      <span class='type'>
        (<tt>Number</tt>)
      </span>
      &mdash;
      <span class='desc'>By default repeat crawls will only process new (previously unprocessed) pages. Set to 0 (<code>onlyProcessIfNew=0</code>) to process all content on repeat crawls. (optional) </span>
    </li>
    <li>
      <span class='name'>maxRounds</span>
      <span class='type'>
        (<tt>Number</tt>)
      </span>
      &mdash;
      <span class='desc'>Specify the maximum number of crawl repeats. Use <code>maxRounds=-1</code> to continually repeat. (optional) </span>
    </li>
  </ul>
</div>
  </div>
</div>
      <h2>Instance Method Details</h2>
      <div class='methods'>
  <div class='method_details'>
    <p class='signature' id='create-dynamic'>
      #
(void)
<b>create</b><span>(callback)</span>
      <span class='bound note'>Bound</span>
      <br>
    </p>
    <div class='docstring'>
  <p>Creates new crawlbot information to DiffBot server</p>
  <div class='examples'>
    <h3>Examples:</h3>
    <h4>
      Basic usage
    </h4>
    <pre><code class='coffeescript'>crawler = client.crawlbot &#39;my-crawler&#39;, [&#39;http:&#47;&#47;domain.com&#39;, &#39;http:&#47;&#47;foo.com&#39;], client.article(&#39;&#39;, [&#39;title&#39;]).url
crawler.create (error, result) -&gt;
  if error?
    console.error error
  else
    console.log result</code></pre>
    <h4>
      Optional parameters
    </h4>
    <pre><code class='coffeescript'>crawler = client.crawlbot &#39;my-crawler&#39;, 
  seeds: [&#39;http:&#47;&#47;domain.com&#39;, &#39;http:&#47;&#47;foo.com&#39;]
  apiUrl: client.article(&#39;&#39;, [&#39;title&#39;]).url
  maxToCrawl: 100

crawler.create (error, result) -&gt;
  if error?
    console.error error
  else
    console.log result</code></pre>
  </div>
</div>
<div class='tags'>
  <h3>Parameters:</h3>
  <ul class='param'>
    <li>
      <span class='name'>callback</span>
      <span class='type'>
        (<tt>Function</tt>)
      </span>
      &mdash;
      <span class='desc'>Callback function (optional) </span>
    </li>
  </ul>
</div>
  </div>
  <div class='method_details'>
    <p class='signature' id='pause-dynamic'>
      #
(void)
<b>pause</b><span>(callback)</span>
      <span class='bound note'>Bound</span>
      <br>
    </p>
    <div class='docstring'>
  <p>Pauses crawlbot job</p>
  <div class='examples'>
    <h3>Examples:</h3>
    <h4>
      Basic usage
    </h4>
    <pre><code class='coffeescript'>crawler = client.crawlbot &#39;my-crawler&#39;
crawler.pause (error, result) -&gt;
  if error?
    console.error error
  else
    console.log result</code></pre>
  </div>
</div>
<div class='tags'>
  <h3>Parameters:</h3>
  <ul class='param'>
    <li>
      <span class='name'>callback</span>
      <span class='type'>
        (<tt>Function</tt>)
      </span>
      &mdash;
      <span class='desc'>Callback function (optional) </span>
    </li>
  </ul>
</div>
  </div>
  <div class='method_details'>
    <p class='signature' id='resume-dynamic'>
      #
(void)
<b>resume</b><span>(callback)</span>
      <span class='bound note'>Bound</span>
      <br>
    </p>
    <div class='docstring'>
  <p>Resumes paused crawlbot job</p>
  <div class='examples'>
    <h3>Examples:</h3>
    <h4>
      Basic usage
    </h4>
    <pre><code class='coffeescript'>crawler = client.crawlbot &#39;my-crawler&#39;
crawler.resume (error, result) -&gt;
  if error?
    console.error error
  else
    console.log result</code></pre>
  </div>
</div>
<div class='tags'>
  <h3>Parameters:</h3>
  <ul class='param'>
    <li>
      <span class='name'>callback</span>
      <span class='type'>
        (<tt>Function</tt>)
      </span>
      &mdash;
      <span class='desc'>Callback function (optional) </span>
    </li>
  </ul>
</div>
  </div>
  <div class='method_details'>
    <p class='signature' id='restart-dynamic'>
      #
(void)
<b>restart</b><span>(callback)</span>
      <span class='bound note'>Bound</span>
      <br>
    </p>
    <div class='docstring'>
  <p>Removes all crawled data while maintaining crawl settings</p>
  <div class='examples'>
    <h3>Examples:</h3>
    <h4>
      Basic usage
    </h4>
    <pre><code class='coffeescript'>crawler = client.crawlbot &#39;my-crawler&#39;
crawler.restart (error, result) -&gt;
  if error?
    console.error error
  else
    console.log result</code></pre>
  </div>
</div>
<div class='tags'>
  <h3>Parameters:</h3>
  <ul class='param'>
    <li>
      <span class='name'>callback</span>
      <span class='type'>
        (<tt>Function</tt>)
      </span>
      &mdash;
      <span class='desc'>Callback function (optional) </span>
    </li>
  </ul>
</div>
  </div>
  <div class='method_details'>
    <p class='signature' id='delete-dynamic'>
      #
(void)
<b>delete</b><span>(callback)</span>
      <span class='bound note'>Bound</span>
      <br>
    </p>
    <div class='docstring'>
  <p>Deletes a crawl, and all associated data, completely.</p>
  <div class='examples'>
    <h3>Examples:</h3>
    <h4>
      Basic usage
    </h4>
    <pre><code class='coffeescript'>crawler = client.crawlbot &#39;my-crawler&#39;
crawler.delete (error, result) -&gt;
  if error?
    console.error error
  else
    console.log result</code></pre>
  </div>
</div>
<div class='tags'>
  <h3>Parameters:</h3>
  <ul class='param'>
    <li>
      <span class='name'>callback</span>
      <span class='type'>
        (<tt>Function</tt>)
      </span>
      &mdash;
      <span class='desc'>Callback function (optional) </span>
    </li>
  </ul>
</div>
  </div>
  <div class='method_details'>
    <p class='signature' id='data-dynamic'>
      #
(void)
<b>data</b><span>(callback)</span>
      <span class='bound note'>Bound</span>
      <br>
    </p>
    <div class='docstring'>
  <p>Returns crawlbot job data</p>
  <div class='examples'>
    <h3>Examples:</h3>
    <h4>
      Basic usage
    </h4>
    <pre><code class='coffeescript'>crawler = client.crawlbot &#39;my-crawler&#39;
crawler.data (error, result) -&gt;
  if error?
    console.error error
  else
    console.log result.data</code></pre>
  </div>
</div>
<div class='tags'>
  <h3>Parameters:</h3>
  <ul class='param'>
    <li>
      <span class='name'>callback</span>
      <span class='type'>
        (<tt>Function</tt>)
      </span>
      &mdash;
      <span class='desc'>Callback function (optional) </span>
    </li>
  </ul>
</div>
  </div>
  <div class='method_details'>
    <p class='signature' id='status-dynamic'>
      #
(void)
<b>status</b><span>(callback)</span>
      <span class='bound note'>Bound</span>
      <br>
    </p>
    <div class='docstring'>
  <p>Returns crawlbot job status</p>
  <div class='examples'>
    <h3>Examples:</h3>
    <h4>
      Basic usage
    </h4>
    <pre><code class='coffeescript'>crawler = client.crawlbot &#39;my-crawler&#39;
crawler.status (error, result) -&gt;
  if error?
    console.error error
  else
    console.log result</code></pre>
  </div>
</div>
<div class='tags'>
  <h3>Parameters:</h3>
  <ul class='param'>
    <li>
      <span class='name'>callback</span>
      <span class='type'>
        (<tt>Function</tt>)
      </span>
      &mdash;
      <span class='desc'>Callback function (optional) </span>
    </li>
  </ul>
</div>
  </div>
</div>
    </div>
    <div id='footer'>
  January 13, 14 02:34:22 by
  <a href='https://github.com/coffeedoc/codo' title='CoffeeScript API documentation generator'>
    Codo
  </a>
  2.0.3
  &#10034;
  Press H to see the keyboard shortcuts
  &#10034;
  <a href='http://twitter.com/netzpirat' target='_parent'>@netzpirat</a>
  &#10034;
  <a href='http://twitter.com/_inossidabile' target='_parent'>@_inossidabile</a>
  &#10034;
  <a href='https://mksoft.ch' target='_parent'>mksoft.ch</a>
</div>
<iframe id='search_frame'></iframe>
<div id='fuzzySearch'>
  <input type='text'>
  <ol></ol>
</div>
<div id='help'>
  <p>
    Quickly fuzzy find classes, mixins, methods, file:
  </p>
  <ul>
    <li>
      <span>T</span>
      Open fuzzy finder dialog
    </li>
  </ul>
  <p>
    Control the navigation frame:
  </p>
  <ul>
    <li>
      <span>L</span>
      Toggle list view
    </li>
    <li>
      <span>C</span>
      Show class list
    </li>
    <li>
      <span>I</span>
      Show mixin list
    </li>
    <li>
      <span>F</span>
      Show file list
    </li>
    <li>
      <span>M</span>
      Show method list
    </li>
    <li>
      <span>E</span>
      Show extras list
    </li>
  </ul>
  <p>
    You can focus and blur the search input:
  </p>
  <ul>
    <li>
      <span>S</span>
      Focus search input
    </li>
    <li>
      <span>Esc</span>
      Blur search input
    </li>
  </ul>
</div>
  </body>
</html>